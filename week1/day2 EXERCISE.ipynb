{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "# MODEL = \"gemma3n:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "# !ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d775488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull gemma3n:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: AI-generated content such as images, videos, and text can be used to create high-quality content for marketing campaigns, social media, and websites.\n",
      "2. **Marketing Automation**: Generative AI can automate tasks such as lead generation, email marketing, and personalized product recommendations, allowing businesses to scale their marketing efforts more efficiently.\n",
      "3. **Product Design**: AI-powered generative design tools can help companies design new products, packaging, and even entire brand identities, reducing the need for manual design expertise.\n",
      "4. **Sales Forecasting**: Generative AI models can analyze historical data and predict future sales trends, enabling businesses to make more informed decisions about inventory management and pricing strategies.\n",
      "5. **Customer Service Chatbots**: AI-powered chatbots can provide 24/7 customer support, responding to common inquiries and routing complex issues to human representatives.\n",
      "6. **Data Analysis and Visualization**: Generative AI can help analyze large datasets, identify patterns, and create visualizations to communicate insights more effectively to stakeholders.\n",
      "7. **Predictive Maintenance**: AI-powered predictive maintenance tools can analyze sensor data from equipment and predict when maintenance is required, reducing downtime and increasing overall efficiency.\n",
      "8. **Content Moderation**: Generative AI can be used to moderate online content, detecting spam, hate speech, and other forms of objectionable material in real-time.\n",
      "9. **Influencer Marketing**: AI-powered tools can analyze social media influencers' performance and recommend new influencers based on specific targeting criteria.\n",
      "10. **Supply Chain Optimization**: Generative AI can help optimize supply chain operations by predicting demand, identifying bottlenecks, and recommending adjustments to inventory management and logistics.\n",
      "11. **Financial Modeling**: AI-powered generative models can create detailed financial forecasts, helping businesses make more informed investment decisions and mitigate risk.\n",
      "12. **Product Development**: Generative AI can aid in product development by generating new ideas, reducing the need for manual prototyping, and accelerating time-to-market.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as blog posts, social media posts, product descriptions, and more, at scale and with minimal human intervention.\n",
      "2. **Image and Video Generation**: Businesses can use generative AI to create custom images, videos, and animations for marketing materials, e-learning content, and other visual projects.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots can provide customer support, answer frequently asked questions, and help with transactional tasks, improving the overall customer experience.\n",
      "4. **Product Design and Prototyping**: Generative AI can assist in product design by generating 2D and 3D models, prototypes, and designs for various industries, including fashion, architecture, and product design.\n",
      "5. **Marketing Automation**: Generative AI can help automate marketing efforts by creating personalized content, social media posts, and email campaigns based on customer data and behavior.\n",
      "6. **Sales Enablement**: Generative AI can create customized sales materials, such as pitches, presentations, and case studies, to help sales teams close deals more effectively.\n",
      "7. **Data Analysis and Insights**: Generative AI can analyze large datasets, identify patterns, and provide insights that can inform business decisions, improve operations, and optimize strategies.\n",
      "8. **Risk Management**: Generative AI can analyze financial data, identify potential risks, and provide predictive models to help businesses mitigate risks and make informed decisions.\n",
      "9. **Supply Chain Optimization**: Generative AI can optimize supply chain logistics, predict demand, and suggest strategies to reduce costs and improve efficiency.\n",
      "10. **Creative Collaboration**: Generative AI can collaborate with human creatives, such as writers, designers, and artists, to generate new ideas, explore different perspectives, and accelerate the creative process.\n",
      "\n",
      "Some specific examples of businesses that are using generative AI include:\n",
      "\n",
      "* **Nike**: Using generative AI to design custom sneakers and athletic wear\n",
      "* **Amazon**: Using generative AI to power its Alexa virtual assistant and personalize customer experiences\n",
      "* **BMW**: Using generative AI to create customized car designs and prototypes\n",
      "* **The New York Times**: Using generative AI to create personalized news articles and recommendations for readers\n",
      "* **Unilever**: Using generative AI to optimize supply chain logistics and predict demand\n",
      "\n",
      "These are just a few examples of the many businesses that are leveraging generative AI to drive innovation, improve operations, and enhance customer experiences.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can create high-quality content, such as articles, social media posts, product descriptions, and even entire books. This automates content creation tasks, freeing up human writers and editors to focus on higher-level creative work.\n",
      "\n",
      "2. **Graphic Design**: Generative AI-powered design tools can generate logos, icons, patterns, and other visual elements quickly and efficiently. This reduces the time and cost associated with traditional graphic design processes.\n",
      "\n",
      "3. **Product Development**: Generative AI can help designers create new product ideas by generating 3D models, prototypes, and even entire product lines. This accelerates the product development process and decreases costs.\n",
      "\n",
      "4. **Customer Service Chatbots**: Generative AI-powered chatbots can respond to customer inquiries, providing 24/7 support and improving customer satisfaction. These chatbots can also be trained to resolve complex issues more efficiently than human customer service reps.\n",
      "\n",
      "5. **Marketing Automation**: Generative AI algorithms can analyze marketing data, identifying trends and opportunities for targeted campaigns. This allows marketers to automate and personalize their marketing efforts, increasing ROI and reducing campaign costs.\n",
      "\n",
      "6. **Finance and Trading**: Generative AI can analyze financial data, identify market patterns, and provide predictions on future market trends. This helps traders and investors make more informed decisions and minimize risk.\n",
      "\n",
      "7. **Customer Segmentation**: Generative AI algorithms can segment customers based on their behavior, preferences, and demographics, allowing businesses to tailor their marketing efforts and improve customer retention.\n",
      "\n",
      "8. **Predictive Maintenance**: Generative AI-powered predictive maintenance tools can analyze sensor data from equipment and machines, predicting potential failures and reducing downtime by scheduling maintenance.\n",
      "\n",
      "9. **Data Enrichment and Analysis**: Generative AI can analyze large datasets, identifying trends, patterns, and insights that may be missed by human analysts. This enhances data analysis capabilities and helps businesses extract more value from their data assets.\n",
      "\n",
      "10. **Innovation Incubation**: Generative AI tools can help automate the exploration of new ideas and concepts by generating text, images, or 3D models based on user research questions or prompts.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out how someone might define \"LLMs\" (Large Language Models), starting with understanding what each part means. The user mentioned three main points: neural networks, attention, and transformers.\n",
      "\n",
      "First, neural networks. I know that they have something to do with machines learning patterns from data automatically, right? So maybe a neural network is like a complex system of nodes connected in layers, processing information to perform tasks like speech or image recognition. But how does it relate to LLMs?\n",
      "\n",
      "Then there's attention, which the user mentioned. I remember that attention is about paying attention or focusing on certain parts of data more than others. It must be crucial in tasks where relevant features matter more, like translating languages or processing text.\n",
      "\n",
      "The third part is transformers. The term \"transformer\" rings a bellâ€”maybe each word encodes something as the model processes them? I think attention seems to be a key component here because models might process words and their context by shifting words and looking at their representations relative to each other.\n",
      "\n",
      "Putting it all together, an LLM probably operates with a neural network that has multiple layers processing information. Attention ensures that each part of the data is relevant, helping the model understand when certain features are important. The transformers mechanism allows the model to handle input sequences in a way that captures interactions between words effectively. The whole system must work behind the scenes to perform tasks like generating text.\n",
      "\n",
      "Wait, but I'm not entirely sure how all these elements come together without getting too deep into details. Maybe it's just that neural networks are the core layer, attention is part of processing data dynamically when needed, and transformers handle the sequence-based interaction within each word or token. So an LLM is all about using these components to model and generate complex languages effectively.\n",
      "\n",
      "I think I have a basic idea now, but I should check if there's any other component I'm missing. Oh, maybe the role of multiple layers in the neural network? That would allow the model to capture more intricate patterns and dependencies in the text input. Also, how does this all tie for generating coherent outputs by the LLM? It seems like attention is key when the model decides where to focus its processing, ensuring that each word's relevant parts contribute appropriately.\n",
      "\n",
      "So, summarizing: An LLM uses a neural network with multiple layers to process sequences of data (like text). Attention mechanisms within the system help prioritize and focus on different parts of the input or interaction steps. The transformer approach processes tokens in parallel while maintaining context through self-attention, enabling models to handle long-range dependencies. All these components come together for the LLM to generate, understand, and output meaningfully generated outputs.\n",
      "</think>\n",
      "\n",
      "A Large Language Model (LLM) is a sophisticated system designed to process and generate human-like text. Here's an organized overview of how it uses core concepts:\n",
      "\n",
      "1. **Neural Network Core**:\n",
      "   - The heart of an LLM is a neural network with multiple layers. These layers are structured into input, hidden, and output sections, enabling the model to learn intricate patterns from data, making them effective for tasks like speech-to-text conversion or photo-to-words translation.\n",
      "\n",
      "2. **Attention Mechanism**:\n",
      "   - Attention focuses on paying attention to specific parts of data when performing tasks, such as translating languages. It ensures that relevant features are emphasized more than others, enhancing task performance by highlighting pertinent information dynamically during processing.\n",
      "\n",
      "3. **Transformers Approach**:\n",
      "   - The \"transformer\" component allows models to process input sequences by considering word representations relative to each other through self-attention. This mechanism enables the model to handle long-range dependencies effectively, a capability crucial for complex language tasks.\n",
      "\n",
      "4. **Integration and Functionality**:\n",
      "   - All these elements work together within an LLM's structure, which processes input sequentially or in parallel while maintaining context through attention. This integration allows the model to generate meaningful outputs by focusing on pertinent features and capturing sequence-related interactions dynamically.\n",
      "\n",
      "In essence, an LLM is a neural network with multiple layers that applies attention mechanisms internally. The transformers approach integrates word processing with self-attention for efficient handling of sequence-based interactions. Together, these components enable effective language modeling, generation, and understanding.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7504106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I want to understand what LLMs are all about. I've heard people talk about them in relation to AI, but I'm not exactly sure how it all fits together. Let me start by breaking down the question they asked. They wanted definitions for three main concepts: neural networks, attention, and transformers. \n",
       "\n",
       "First off, I know that LLMs are a type of machine learning model specifically designed for natural language processing tasks. But to be honest, I'm not entirely sure what that means beyond just any AI system handling text. So maybe the starting point is explaining neural networks in general.\n",
       "\n",
       "Wait, but hold on. They also want me to include attention and transformers within these definitions without losing track. So perhaps it's more precise than I initially thought. Maybe I should structure each concept as a separate item first.\n",
       "\n",
       "Starting with neural networks: I remember that they are inspired by the human brain, having layers of interconnected nodes or neurons. These layers process information through connections. But how does this specifically apply to LLMs? Well, since LLMs do text processing, their input layer likely handles the text as a sequence of tokenized words. Each token is maybe passed through some hidden layers which act like neural networks trying to learn patterns.\n",
       "\n",
       "But I'm not entirely sure about the role of multiple hidden layers and weights in this context. Maybe each layer does something specific? Also, they often use techniques like normalization, activation functions, cross-entropy loss for training models effectively.\n",
       "\n",
       "Now, moving on to attention. The user mentioned it's a core concept, so it can't be too abstract. I think attention mechanisms allow the model to focus on different parts of the input when processing text or other sequences. This is crucial because without attention, the model would process all tokens equally, losing important contextual information.\n",
       "\n",
       "But how does this work exactly? Maybe each token has an attention mask that indicates which weights it should attend to. So during training, other models adjust this to preserve important context while others ignore irrelevant parts. That makes sense because context is key in understanding what a word means in a sentence.\n",
       "\n",
       "Then the transformers part. A transformer-based model refers to models where the processing happens sequentially rather than using layers of hidden layers as with neural networks traditionally. This was popularized by paper work done by Vaswani et al., introducing \"attention is all you need.\"\n",
       "\n",
       "I think that traditional RNNs process sequences step by step, but transformers use parallel distributed processing and attention mechanisms internally to manage the context layers without external control. So each block in a transformer processes different parts of the sequence while others focus on various aspects at once.\n",
       "\n",
       "Putting it all together, LLMs as neural networks with attention units and a sequence-modelling approach using transformers. All these components work towards accurate text understanding by leveraging these advanced machine learning and AI principles.\n",
       "\n",
       "I'm still trying to grasp how attention within transformers specifically allows for flexible focus without overcomplicating the model structure. Maybe it's all about the way information is mapped between different parts of the network, enabling better alignment of representations across input tokens without explicit control from the user.\n",
       "\n",
       "Overall, I feel like I have a basic understanding now, but I still have to clarify any gaps or uncertainties. Maybe looking up examples of LLMs like ChatGPT could help solidify these concepts further.\n",
       "</think>\n",
       "\n",
       "LLMs are advanced AI models designed for text processing, as mentioned earlier. Here's a detailed explanation of the key components you asked about:\n",
       "\n",
       "### Neural Networks:\n",
       "NNs in this context are inspired by biological neural networks. They consist of layers of interconnected neurons, each representing a node processing information through connections to other nodes. In LLMs, these networks process text input by handling it token-wise (tokenized words). Each token is passed through multiple hidden layers, which act like neural networks learning patterns and relationships in data. The activation functions, like ReLU, provide non-linearity for mapping inputs to outputs, while loss functions such as cross-entropy help optimize model performance.\n",
       "\n",
       "### Attention:\n",
       "Attention mechanisms enable the model to focus on different parts of input text or sequences. In transformers, each token has an attention mask indicating which weights it should attend to, allowing the model to preserve context while processing words. This self-attention mechanism in RNNs (as opposed to traditional structures) ensures that each token attends to others strategically, without needing explicit control from users.\n",
       "\n",
       "### Transformers:\n",
       "Transformers are a sequence-modelling class where models process sequences in parallel using distributed attention layers. Each layer operates independently but enhances the context layers through cross-attention, allowing models to capture complex relationships between input tokens without external control. This approach avoids traditional hidden layers and relies on internal mechanisms for processing, as demonstrated in models like ChatGPT, which are effective at natural language tasks.\n",
       "\n",
       "These components together create a powerful framework for LLMs, enabling them to accurately understand text by leveraging advanced neural network concepts with flexible attention mechanisms and transparent sequence modeling."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
